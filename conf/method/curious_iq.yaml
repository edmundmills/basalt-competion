name: 'curious_IQ'
algorithm: 'curious_IQ'
loss_function: 'iqlearn'
loss: 'value'
drq: true
normalize_reward: true


starting_steps: 10000
curiosity_pretraining_steps: 15000  # training on the random data
suppress_snowball_steps: 2000
training_steps: 20000

batch_size: 256
expert_sample_fraction: 0.5

discount_factor: 0.99
curiosity_lr: 1e-3
q_lr: 3e-4
iqlearn_lr: 3e-4
policy_lr: 1e-4

tau: .05

expert_dataset: true
double_q: false
