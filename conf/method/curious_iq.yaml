name: 'curious_IQ'
algorithm: 'curious_IQ'
loss_function: 'iqlearn'
loss: 'value'
drq: true
target_q: true  # for iqlearn q function
curiosity_reward: true
online_curiosity_training: true
normalize_reward: true  # for curiosity rewards
entropy_adjustment: true
target_entropy_ratio: 0.1

starting_steps: 10000
curiosity_pretraining_steps: 15000  # training on the random data
suppress_snowball_steps: 2000
curiosity_only_steps: 20000
initial_curiosity_fraction: 0.5
curiosity_fade_out_steps: 20000
training_steps: 50000

batch_size: 256
expert_sample_fraction: 0.5

discount_factor: 0.99
curiosity_lr: 1e-3
q_lr: 3e-4
iqlearn_lr: 3e-4
policy_lr: 1e-4
entropy_lr: 1e-3

tau: .05

expert_dataset: true
double_q: false
