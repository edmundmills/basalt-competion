name: 'iqlearn_sac'
algorithm: 'curious_IQ'
loss_function: 'iqlearn'
loss: 'value'
drq: true
target_q: true  # for iqlearn q function
entropy_adjustment: true


starting_steps: 5000
suppress_snowball_steps: 2000
training_steps: 30000

curiosity_reward: false
online_curiosity_training: false
initial_curiosity_fraction: 0
curiosity_pretraining_steps: 0  # training on the random data
curiosity_only_steps: 0
curiosity_fade_out_steps: 0
normalize_reward: false  # for curiosity rewards


batch_size: 256
expert_sample_fraction: 0.5

discount_factor: 0.99
curiosity_lr: 0
q_lr: 0
iqlearn_lr: 3e-4
policy_lr: 1e-4
entropy_lr: 1e-3

tau: .05

expert_dataset: true
double_q: false
