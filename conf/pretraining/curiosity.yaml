name: 'curiosity_pretraining'
algorithm: 'curiosity_pretraining'
drq: true
normalize_reward: true


starting_steps: 10000
curiosity_pretraining_steps: 5000  # training on the random data
suppress_snowball_steps: 2000
training_steps: 20000

batch_size: 256
discount_factor: 0.99
curiosity_lr: 1e-3
q_lr: 3e-4
policy_lr: 1e-4

tau: .05
double_q: false

expert_dataset: false
